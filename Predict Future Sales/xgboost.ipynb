{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal:\n",
    "- predict total sales for every product and store in the next month\n",
    "\n",
    "### Data Info\n",
    "- item_cnt_day: num of products sold (predicting a monthly amount of this measure)\n",
    "- date_block_num: January 2013 is 0, February 2013 is 1,..., October 2015 is 33\n",
    "\n",
    "### Procedure:\n",
    "- Get the items_id from test dataset\n",
    "    - Get the test items not appear in train dataset, fill with 0 vlaues for validation\n",
    "    - Get the tuple(ShopID, item) for training dataset (take shop into account)\n",
    "- Based on item_lst, Feature Engineering on dataset\n",
    "- Apply one xgboost model \n",
    "- Apply one time series modeling\n",
    "\n",
    "## Preprocess\n",
    "- datetime\n",
    "- sum up sales on a monthly basis\n",
    "- Remove outliers \n",
    "- fill the month num without item_cnt_day sum with 0 value\n",
    "- Fill the nan value\n",
    "\n",
    "### Features\n",
    "- seasonality\n",
    "    - month\n",
    "    - date_cat_avg_item_cnt\n",
    "    - date_block_num\n",
    "    - item_cnt_month \n",
    "- shops\n",
    "    - date_shop_cat_avg_item_cnt\n",
    "- items\n",
    "    - item_category_id\t\n",
    "    - delta_price_lag\n",
    "    - item_id\n",
    "    - date_cat_avg_item_cnt\n",
    "    - date_item_avg_item_cnt\n",
    "    - item_avg_item_price\n",
    "    - date_item_avg_item_price\n",
    "    - price_change_percent\n",
    "\n",
    "\n",
    "### Top features\n",
    "- date_item_avg_item_cnt\n",
    "- item_category_id\t\n",
    "- month\n",
    "- date_cat_avg_item_cnt\n",
    "- delta_price_lag\n",
    "- item_id\n",
    "\n",
    "### Label\n",
    "- col `item_cnt_day`\n",
    "\n",
    "\n",
    "### Model (XGBoost)\n",
    "- Train data -- week 0-32\n",
    "- Valid data -- week 33\n",
    "\n",
    "### Post Process Approach\n",
    "- Take 25% high (shop,item) tuple with item_cnt_month, (median of last 4 or 5 month in last year), replace the pred value with the median and clip (0,20) \n",
    "- take the median value of all shop and items from first to last year, get all (items, shop) for median with 0, replace their value with 0 &\n",
    "- take the tuple not appear in train set but in test set, replace the pred val with 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges\n",
    "- matrix are too large to process\n",
    "    - there are 3570291 input entries for model input\n",
    "- there are huge infrequent items sold for training period\n",
    "    - 75% of data have sold items less than 5 months out of 2 year and half\n",
    "- (shop, items) appear in test set not in train set\n",
    "\n",
    "### Approach\n",
    "- Use spark dataframe to process large dataset in parallel\n",
    "- Add more features for model training\n",
    "- Train frequent and infrequent items separately\n",
    "- Make the (shop, items) tuple in test set label as 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set\n",
    "- test set have 42 unique shops id, 5100 unique items, ttl shape: 214200 (5100*42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "from itertools import product\n",
    "import time\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape:  (2935849, 6)\n",
      "         date  date_block_num  shop_id  item_id  item_price  item_cnt_day\n",
      "0  02.01.2013               0       59    22154      999.00           1.0\n",
      "1  03.01.2013               0       25     2552      899.00           1.0\n",
      "2  05.01.2013               0       25     2552      899.00          -1.0\n",
      "3  06.01.2013               0       25     2554     1709.05           1.0\n",
      "4  15.01.2013               0       25     2555     1099.00           1.0\n"
     ]
    }
   ],
   "source": [
    "# merge train with item data\n",
    "def file_loc(path):\n",
    "    filename = 'data/'\n",
    "    file_dir = os.path.join(filename,path)\n",
    "    return file_dir\n",
    "\n",
    "train_file = file_loc('sales_train.csv')\n",
    "item_file = file_loc('items.csv')\n",
    "shops_file = file_loc('shops.csv')\n",
    "item_cate_file = file_loc('item_categories.csv')\n",
    "test = file_loc('test.csv')\n",
    "\n",
    "df_train = pd.read_csv(train_file)\n",
    "df_item = pd.read_csv(item_file)\n",
    "df_shops = pd.read_csv(shops_file)\n",
    "df_item_cate = pd.read_csv(item_cate_file)\n",
    "df_test = pd.read_csv(test)\n",
    "\n",
    "print('training data shape: ', df_train.shape)\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>date</th>\n",
       "      <th>item_price</th>\n",
       "      <th>item_cnt_day</th>\n",
       "      <th>item_name</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>month</th>\n",
       "      <th>shop_item_sum_month</th>\n",
       "      <th>...</th>\n",
       "      <th>date_cat_avg_item_cnt</th>\n",
       "      <th>item_avg_item_price</th>\n",
       "      <th>date_item_avg_item_price</th>\n",
       "      <th>year</th>\n",
       "      <th>shop_item_month_year</th>\n",
       "      <th>item_month_year</th>\n",
       "      <th>shop_day_month</th>\n",
       "      <th>item_day_month</th>\n",
       "      <th>shop_item_month</th>\n",
       "      <th>shop_item_month_un</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.812327</td>\n",
       "      <td>170.302401</td>\n",
       "      <td>336.575462</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>65477</td>\n",
       "      <td>728</td>\n",
       "      <td>1007</td>\n",
       "      <td>65477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>499.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1+1 (BD)</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>74.580922</td>\n",
       "      <td>108.304828</td>\n",
       "      <td>391.372549</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1325</td>\n",
       "      <td>91</td>\n",
       "      <td>1007</td>\n",
       "      <td>1325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.812327</td>\n",
       "      <td>19.731225</td>\n",
       "      <td>15.090909</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>65477</td>\n",
       "      <td>1175</td>\n",
       "      <td>1007</td>\n",
       "      <td>65477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.812327</td>\n",
       "      <td>29.558935</td>\n",
       "      <td>61.558824</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>65477</td>\n",
       "      <td>1185</td>\n",
       "      <td>1007</td>\n",
       "      <td>65477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.812327</td>\n",
       "      <td>34.104661</td>\n",
       "      <td>60.567568</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>65477</td>\n",
       "      <td>1240</td>\n",
       "      <td>1007</td>\n",
       "      <td>65477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_block_num  shop_id  item_id        date  item_price  item_cnt_day  \\\n",
       "0               0        2       32         NaN         0.0           0.0   \n",
       "1               0        2       33  2013-01-05       499.0           1.0   \n",
       "2               0        2       42         NaN         0.0           0.0   \n",
       "3               0        2       45         NaN         0.0           0.0   \n",
       "4               0        2       51         NaN         0.0           0.0   \n",
       "\n",
       "  item_name  item_category_id  month  shop_item_sum_month  ...  \\\n",
       "0         0               0.0    0.0                  0.0  ...   \n",
       "1  1+1 (BD)              37.0    1.0                  1.0  ...   \n",
       "2         0               0.0    0.0                  0.0  ...   \n",
       "3         0               0.0    0.0                  0.0  ...   \n",
       "4         0               0.0    0.0                  0.0  ...   \n",
       "\n",
       "   date_cat_avg_item_cnt  item_avg_item_price  date_item_avg_item_price  \\\n",
       "0              10.812327           170.302401                336.575462   \n",
       "1              74.580922           108.304828                391.372549   \n",
       "2              10.812327            19.731225                 15.090909   \n",
       "3              10.812327            29.558935                 61.558824   \n",
       "4              10.812327            34.104661                 60.567568   \n",
       "\n",
       "     year  shop_item_month_year  item_month_year  shop_day_month  \\\n",
       "0  2013.0                   1.0             13.0           65477   \n",
       "1  2013.0                   4.0             13.0            1325   \n",
       "2  2013.0                   1.0             12.0           65477   \n",
       "3  2013.0                   1.0             13.0           65477   \n",
       "4  2013.0                   1.0             13.0           65477   \n",
       "\n",
       "   item_day_month  shop_item_month  shop_item_month_un  \n",
       "0             728             1007               65477  \n",
       "1              91             1007                1325  \n",
       "2            1175             1007               65477  \n",
       "3            1185             1007               65477  \n",
       "4            1240             1007               65477  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_1 = pd.read_csv('preprocess_matrix.csv', low_memory=False)\n",
    "matrix_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess\n",
    "- datetime\n",
    "- sum up on a monthly basis\n",
    "- take care of outliers -- clip\n",
    "- fill the month num without item_cnt_day sum with 0 value\n",
    "\n",
    "### Label\n",
    "- col `item_cnt_day`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# items in test set to train set\n",
    "test_id_lst = df_test['item_id'].unique().tolist()\n",
    "df_train_item = df_train_pro.loc[df_train_pro['item_id'].isin(test_id_lst)]\n",
    "val = (5100-4737)/5100\n",
    "\n",
    "print('total_item_test_len: ', len(test_id_lst))\n",
    "print('total_item_train_len: ', len(df_train_item['item_id'].unique()))\n",
    "print('null test_id percentage in train_data: ', val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# items in test set to train set\n",
    "test_item_lst = df_test['item_id'].unique().tolist()\n",
    "test_shop_lst = df_test['shop_id'].unique().tolist()\n",
    "df_train_item = df_train_pro.loc[(df_train_pro['item_id'].isin(test_item_lst)) & (df_train_pro['shop_id'].isin(test_shop_lst))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process into datetime\n",
    "df_train_item['date'] = pd.to_datetime(df_train_item['date'], format='%d.%m.%Y')\n",
    "df_train_item['month'] = df_train_item['date'].dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.xlim(-100, 3000)\n",
    "sns.boxplot(x=df_train_item['item_cnt_day'])\n",
    "print('Sale volume outliers:',df_train_item['item_id'][df_train_item['item_cnt_day']>500].unique())\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.xlim(df_train_item['item_price'].min(), df_train_item['item_price'].max())\n",
    "sns.boxplot(x=df_train_item['item_price'])\n",
    "print('Item price outliers:',df_train_item['item_id'][df_train_item['item_price']>50000].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_no_out = df_train_item.loc[(df_train_item['item_cnt_day']<500) & (df_train_item['item_price']<40000)]\n",
    "print('before remove outlier shape: ', df_train_item.shape)\n",
    "print('after remove outlier shape: ', df_train_no_out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product function\n",
    "- take the month, shop, and items product together\n",
    "\n",
    "### create df\n",
    "    - See all shops which sell items, items being sold at that month\n",
    "    - have the rows prepared for that month with the combination of items and shops\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "matrix = []\n",
    "cols = ['date_block_num','shop_id','item_id']\n",
    "for i in range(34):\n",
    "    sales = df_train_no_out[df_train_no_out.date_block_num==i]\n",
    "    matrix.append(np.array(list(product([i], sales.shop_id.unique(), sales.item_id.unique())), dtype='int16'))\n",
    "    \n",
    "matrix = pd.DataFrame(np.vstack(matrix), columns=cols)\n",
    "matrix.sort_values(cols,inplace=True)\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "\n",
    "matrix = pd.merge(matrix, df_train_no_out, on=cols, how='left')\n",
    "matrix['shop_item_sum_month'] = matrix.groupby(['date_block_num','shop_id','item_id'])['item_cnt_day'].transform('sum')\n",
    "matrix['shop_item_sum_month'] = (matrix['shop_item_sum_month']\n",
    "                                .fillna(0)\n",
    "                                .clip(0,20) # NB clip target here\n",
    "                                .astype(np.float16))\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['date_block_num'] = 34\n",
    "matrix = pd.concat([matrix, df_test], ignore_index=True, sort=False, keys=cols)\n",
    "matrix.fillna(0, inplace=True) # 34 month\n",
    "matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill the nan value\n",
    "- item_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item_mean = matrix.groupby(['item_id'])['item_price'].mean().reset_index()\n",
    "df_item_cate_median = matrix.groupby(['item_id'])['item_category_id'].median().reset_index()\n",
    "\n",
    "for item in matrix['item_id'].unique().tolist():\n",
    "    mean_price = df_item_mean.loc[df_item_mean['item_id']==item, 'item_price'].values[0]\n",
    "    matrix.loc[(matrix['item_id']==item) & (matrix['item_price'].isnull()), 'item_price'] = mean_price\n",
    "    matrix['item_cnt_day'].fillna(0, inplace=True)\n",
    "    item_cate = df_item_cate_median.loc[df_item_cate_median['item_id']==item, 'item_category_id'].values[0]\n",
    "    matrix.loc[(matrix['item_id']==item) & (matrix['item_category_id'].isnull()), 'item_category_id'] = item_cate\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incorporate shop and item feature\n",
    "\n",
    "# incorporate item feature\n",
    "matrix['item_cnt_month'] = matrix.groupby(['date_block_num', 'item_id'])['item_cnt_day'].transform('sum')\n",
    "# every month, items sold mean\n",
    "matrix['date_item_avg_item_cnt'] = matrix.groupby(['date_block_num', 'item_id'])['item_cnt_day'].transform('mean')\n",
    "# incorporate shop and cate feature\n",
    "matrix['date_shop_cat_avg_item_cnt'] = matrix.groupby(['date_block_num', 'shop_id', 'item_category_id'])['item_cnt_month'].transform('mean')\n",
    "# cate\n",
    "matrix['date_cat_avg_item_cnt'] = matrix.groupby(['date_block_num', 'item_category_id'])['item_cnt_month'].transform('mean')\n",
    "# feature delta_price\n",
    "matrix['item_avg_item_price'] = matrix.groupby(['item_id'])['item_price'].transform('mean')\n",
    "# \n",
    "matrix['date_item_avg_item_price'] = matrix.groupby(['date_block_num', 'item_id'])['item_price'].transform('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix['date'] = pd.to_datetime(matrix['date'], format='%Y-%m-%d', errors='coerce')\n",
    "matrix['year'] = matrix['date'].dt.year\n",
    "date_year_dict = {}\n",
    "for month in matrix['date_block_num'].unique():\n",
    "    try:\n",
    "        val = matrix.loc[(matrix['date_block_num']==month) & (matrix['year'].notnull()), 'year'].values[0]\n",
    "        date_year_dict[month] = val\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "date_year_dict[34]=2015.0\n",
    "matrix['year'] = matrix['date_block_num'].map(date_year_dict)\n",
    "\n",
    "# a year feature --  See shop sold items on nums of months\n",
    "matrix['shop_item_month_year'] = matrix.groupby(['shop_id', 'item_id', 'year'])['month'].transform('nunique')\n",
    "# a year feature --  See items sold on nums of months\n",
    "matrix['item_month_year'] = matrix.groupby(['item_id', 'year'])['month'].transform('nunique')\n",
    "\n",
    "\n",
    "# a month feature --  See shop sold on nums of days\n",
    "matrix['shop_day_month'] = matrix.groupby(['shop_id','month'])['item_cnt_day'].transform('count')\n",
    "# a month feature --  See items sold on nums of days\n",
    "matrix['item_day_month'] = matrix.groupby(['item_id', 'month'])['item_cnt_day'].transform('count')\n",
    "\n",
    "# a month feature\n",
    "matrix['shop_item_month'] = matrix.groupby(['shop_id', 'date_block_num'])['item_id'].transform('count')\n",
    "# a month feature\n",
    "matrix['shop_item_month_un'] = matrix.groupby(['shop_id', 'month'])['item_id'].transform('count')\n",
    "# Add 1 feature with existing sold month in a year\n",
    "matrix['date_shop_cat_avg_item_cnt'] = matrix.groupby(['date_block_num', 'shop_id', 'item_category_id'])['item_cnt_month'].transform('mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_train_item_month = matrix.drop_duplicates(['date_block_num', 'item_id', 'shop_id'])\n",
    "matrix_train_item_month.sort_values(by=['date_block_num'], inplace=True)\n",
    "# item_price shift\n",
    "matrix_train_item_month['item_price_last'] = matrix_train_item_month.groupby(['item_id'])['item_price'].shift(periods=1, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features for model Input\n",
    "- date_block_num\n",
    "- item_id\n",
    "- item_price (scale)\n",
    "- month\n",
    "- item_category_id\n",
    "- item_cnt_month (scale)\n",
    "- date_item_avg_item_cnt (scale)\n",
    "- date_shop_cat_avg_item_cnt (scale)\n",
    "- date_cat_avg_item_cnt (scale)\n",
    "- item_avg_item_price (scale)\n",
    "- date_item_avg_item_price (scale)\n",
    "- price_change_percent(scale)\n",
    "- shop_item_sum_month (label)\n",
    "\n",
    "### Model (XGBoost)\n",
    "- Train data -- week 32\n",
    "- Valid data -- week 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify the index order\n",
    "# exclude 2 cols : 'shop_item_month_year', 'item_month_year'\n",
    "col_lst = ['date_block_num', 'item_id', 'shop_id', 'item_price', 'month', 'item_category_id', 'item_cnt_month', \n",
    "          'date_item_avg_item_cnt', 'date_shop_cat_avg_item_cnt', 'date_cat_avg_item_cnt', 'item_avg_item_price',\n",
    "           'date_item_avg_item_price', \n",
    "         'shop_day_month', 'item_day_month', 'shop_item_month_un', 'shop_item_month']\n",
    "df_model = matrix_train_item_month[col_lst]\n",
    "matrix_train_item_month['shop_item_sum_month'] = matrix_train_item_month['shop_item_sum_month'].clip(0,20)\n",
    "matrix_train_item_month['shop_item_sum_month'] = matrix_train_item_month['shop_item_sum_month'].astype(int)\n",
    "X_train = df_model[df_model.date_block_num < 33]\n",
    "X_train.sort_values(by=['date_block_num', 'shop_id','item_id'], inplace=True)\n",
    "y_train = matrix_train_item_month.loc[matrix_train_item_month.date_block_num < 33, 'shop_item_sum_month'].to_frame()\n",
    "# modify part\n",
    "X_train_idx = X_train.index.values\n",
    "y_train = y_train.reindex(X_train_idx)\n",
    "Y_train = y_train.values\n",
    "X_valid = df_model[df_model.date_block_num == 33]\n",
    "X_valid.sort_values(by=['date_block_num', 'shop_id','item_id'], inplace=True)\n",
    "y_valid = matrix_train_item_month.loc[matrix_train_item_month.date_block_num == 33, 'shop_item_sum_month'].to_frame()\n",
    "# modify part\n",
    "X_valid_idx = X_valid.index.values\n",
    "y_valid = y_valid.reindex(X_valid_idx)\n",
    "Y_valid = y_valid.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run\n",
    "model = XGBRegressor(\n",
    "    max_depth=8,\n",
    "    n_estimators=1000,\n",
    "    min_child_weight=300, \n",
    "    colsample_bytree=0.8, \n",
    "    subsample=0.8, \n",
    "    learning_rate=0.03,    \n",
    "    seed=42)\n",
    "\n",
    "model.fit(\n",
    "    X_train, \n",
    "    Y_train, \n",
    "    eval_metric=\"rmse\", \n",
    "    eval_set=[(X_train, Y_train), (X_valid, Y_valid)], \n",
    "    verbose=True, \n",
    "    early_stopping_rounds = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_model[df_model.date_block_num == 34]\n",
    "X_test.sort_values(by=['date_block_num', 'shop_id', 'item_id'], inplace=True)\n",
    "\n",
    "col_lst = ['date_block_num', 'item_id', 'shop_id', 'item_price', 'month', 'item_category_id', 'item_cnt_month', \n",
    "          'date_item_avg_item_cnt', 'date_shop_cat_avg_item_cnt', 'date_cat_avg_item_cnt', 'item_avg_item_price',\n",
    "           'date_item_avg_item_price', \n",
    "         'shop_day_month', 'item_day_month', 'shop_item_month_un', 'shop_item_month']\n",
    "test_merge_df = X_test[col_lst]\n",
    "\n",
    "Y_pred = model.predict(X_valid).clip(0, 20)\n",
    "Y_test = model.predict(test_merge_df).clip(0, 20)\n",
    "\n",
    "# save predictions for an ensemble\n",
    "pickle.dump(Y_pred, open('xgb_train.pickle', 'wb'))\n",
    "pickle.dump(Y_test, open('xgb_test.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach\n",
    "- Take 25% high (shop,item) tuple with item_cnt_month, (median of last 4 or 5 month in last year), replace the pred value with the median and clip (0,20)\n",
    "- take the median value of all shop and items from first to last year, get all (items, shop) for median with 0, replace their value with 0 &\n",
    "- take the tuple not appear in train set but in test set, replace the pred val with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_train_item_month = pd.read_csv('/kaggle/input/largematrix/large_matrix_trained_mdl.csv')\n",
    "# load xgb model prediction\n",
    "submission = pd.DataFrame({\n",
    "    \"ID\": df_test.ID, \n",
    "    \"item_cnt_month\": xgb_model_pred\n",
    "})\n",
    "\n",
    "test_shop_lst = df_test['shop_id'].unique().tolist()\n",
    "test_item_lst = df_test['item_id'].unique().tolist()\n",
    "matrix_test_year = matrix_train_item_month.loc[(matrix_train_item_month['year']==matrix_train_item_month['year'].max()) &\n",
    "                            (matrix_train_item_month['shop_id'].isin(test_shop_lst)) &\n",
    "                           (matrix_train_item_month['item_id'].isin(test_item_lst))]\n",
    "row, col = matrix_test_year.shape\n",
    "top_30 = row*0.25\n",
    "int_top_30 = \"%.0f\" % top_30\n",
    "\n",
    "# extracting top 25%\n",
    "large30_pct = matrix_test_year.nlargest(int(int_top_30), \"shop_item_sum_month\") \n",
    "top30_shop_item = list(zip(large30_pct['shop_id'], large30_pct['item_id']))\n",
    "\n",
    "top30_shop_lst = []\n",
    "df_median = matrix_test_year.groupby(['shop_id', 'item_id'])['shop_item_sum_month'].median().reset_index()\n",
    "for (shop, item) in top30_shop_item:\n",
    "    val = df_median.loc[(df_median['shop_id']==shop) & (df_median['item_id']==item), 'shop_item_sum_month'].values[0]\n",
    "    top30_shop_lst.append(val)\n",
    "\n",
    "submission1 = pd.merge(df_test, submission, on=['ID'])\n",
    "for (shop, item), month_sales in zip(top30_shop_item, top30_shop_lst):\n",
    "    \n",
    "    submission1.loc[(submission1['shop_id']==shop) & (submission1['item_id']==item), 'item_cnt_month'] = month_sales\n",
    "top30_shop_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc train data median with 0\n",
    "matrix_test_year = matrix_train_item_month.loc[\n",
    "                            (matrix_train_item_month['shop_id'].isin(test_shop_lst)) &\n",
    "                           (matrix_train_item_month['item_id'].isin(test_item_lst))]\n",
    "\n",
    "df_median = matrix_test_year.groupby(['shop_id', 'item_id'])['shop_item_sum_month'].median().reset_index()\n",
    "df_median0 = df_median.loc[df_median['shop_item_sum_month']==0]\n",
    "med0_shop_item = list(zip(df_median0['shop_id'], df_median0['item_id']))\n",
    "for (shop, item) in med0_shop_item:\n",
    "    \n",
    "    submission1.loc[(submission1['shop_id']==shop) & (submission1['item_id']==item), 'item_cnt_month'] = 0\n",
    "\n",
    "df_median0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc test tuple (shop, item) only in test not in train\n",
    "df_train_no_test = pd.merge(df_train, df_test, on=['shop_id', 'item_id'], how='right')\n",
    "df_train_no_test1 = df_train_no_test.loc[df_train_no_test['item_cnt_day'].isnull()]\n",
    "train_no_test_item_lst = df_train_no_test1['item_id'].unique().tolist()\n",
    "train_no_test_shop_lst = df_train_no_test1['shop_id'].unique().tolist()\n",
    "\n",
    "tup_lst = list(zip(df_train_no_test1['shop_id'], df_train_no_test1['item_id']))\n",
    "\n",
    "for (shop, item) in tup_lst:\n",
    "    \n",
    "    submission1.loc[(submission1['shop_id']==shop) & (submission1['item_id']==item), 'item_cnt_month'] = 0\n",
    "\n",
    "print('completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission2 = submission1[['ID', 'item_cnt_month']]\n",
    "submission2.to_csv('xgb_submission_36.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
