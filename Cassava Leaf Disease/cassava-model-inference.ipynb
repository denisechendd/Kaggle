{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# install the python package without the internet\n! pip install --no-index --find-links /kaggle/input/timmpackage1/ timm\n! pip install --no-index --find-links=/kaggle/input/visiontransformerpkg1/ vision_transformer_pytorch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from glob import glob\nfrom sklearn.model_selection import GroupKFold, StratifiedKFold\nimport cv2\nfrom skimage import io\nimport torch\nfrom sklearn.preprocessing import LabelBinarizer\nfrom torch import nn\nimport os\nfrom datetime import datetime\nimport time\nimport random\nimport cv2\nimport torchvision\nfrom torchvision import transforms\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch.utils.data.sampler import SequentialSampler, RandomSampler\nfrom torch.cuda.amp import autocast, GradScaler\nimport torch.nn.functional as F\nfrom vision_transformer_pytorch import VisionTransformer\n\nimport sklearn\nimport warnings\nimport joblib\nfrom sklearn.metrics import roc_auc_score, log_loss\nfrom sklearn import metrics\nimport warnings\nimport cv2\nimport pydicom\nimport timm #from efficientnet_pytorch import EfficientNet\nfrom scipy.ndimage.interpolation import zoom\nfrom sklearn.metrics import log_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CFG = {\n    'fold_num': 5,\n    'seed': 719,\n    'model_efficientnet': 'tf_efficientnet_b4_ns',\n    'model_resnext50': 'resnext50_32x4d',\n    'img_size': 384, #448, #512\n    'epochs': 10,\n    'train_bs': 32,\n    'valid_bs': 32,\n    'lr': 1e-4,\n    'num_workers': 4,\n    'accum_iter': 1, # suppoprt to do batch accumulation for backprop with effectively larger batch size\n    'verbose_step': 1,\n    'device': 'cuda:0',\n    'tta': 3,\n    'used_epochs': [6,7,8,9],\n    'weights': [1,1,1,1, 1,1]\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/cassava-leaf-disease-classification/train.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\ndef get_img(path):\n    im_bgr = cv2.imread(path)\n    im_rgb = im_bgr[:, :, ::-1]\n    #print(im_rgb)\n    return im_rgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CassavaDataset(Dataset):\n    # CassavaDataset function: return the transformed image file\n    def __init__(\n        self, df, data_root, transforms=None, output_label=True\n    ):\n        super().__init__()\n        self.df = df.reset_index(drop=True).copy()\n        self.transforms = transforms\n        self.data_root = data_root\n        self.output_label = output_label\n    \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self, index: int):\n        \n        # get labels\n        if self.output_label:\n            target = self.df.iloc[index]['label']\n          \n        path = \"{}/{}\".format(self.data_root, self.df.iloc[index]['image_id'])\n        # extract image array\n        img  = get_img(path)\n        \n        if self.transforms:\n            img = self.transforms(image=img)['image']\n            \n        # do label smoothing\n        if self.output_label == True:\n            return img, target\n        else:\n            return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from albumentations import (\n    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n)\n\nfrom albumentations.pytorch import ToTensorV2\n\nfrom albumentations import (\n    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n)\n\nfrom albumentations.pytorch import ToTensorV2\n\ndef get_train_transforms():\n    return Compose([\n            RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n            Transpose(p=0.5),\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            ShiftScaleRotate(p=0.5),\n            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            CoarseDropout(p=0.5),\n            Cutout(p=0.5),\n            ToTensorV2(p=1.0),\n        ], p=1.)\n\ndef get_valid_transforms():\n    return Compose([\n            CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\n            Resize(CFG['img_size'], CFG['img_size']),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0),\n        ], p=1.)\n\ndef get_inference_transforms():\n    # preprocess the image through a pipeline\n    return Compose([\n            RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n            Transpose(p=0.5),\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            #HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n            #RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0),\n        ], p=1.)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model\nclass CassvaImgClassifier(nn.Module):\n    '''CassvaImgClassifier class: construct the deep learning model\n    input: \n        model_arch: model name\n    '''\n    def __init__(self, model_arch, n_class, pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_arch, pretrained=pretrained)\n        # model is efficientnet\n        if 'efficientnet' in model_arch:\n            n_features = self.model.classifier.in_features\n            self.model.classifier = nn.Linear(n_features, n_class)\n        # model is resnext\n        if 'resnext' in model_arch:\n            n_features = self.model.fc.in_features\n            self.model.fc = nn.Linear(n_features, n_class)\n            \n    def forward(self, x):\n        x = self.model(x)\n        return x\n    \nclass EnsembleClassifier(nn.Module):\n     '''\n     EnsembleClassifier class: Ensemble three models' performance and apply different weights to\n     model prediction\n     input:\n     model_efficientnet: tf_efficientnet_b4_ns model\n     model_resnext50: resnext50_32x4d model'''\n    def __init__(self, model_efficientnet, model_resnext50,n_class, pretrained=False):\n        super().__init__()\n        # load the VisionTransformer model\n        self.model1 = VisionTransformer.from_name('ViT-B_16', num_classes=5) \n        self.model1.load_state_dict(torch.load('/kaggle/input/vitmodel2/ViT-B_16.pt'))\n        print('load VisionTransformer model:', self.model1)\n        self.model2 = CassvaImgClassifier(model_efficientnet, n_class, pretrained)\n        print('load efficientnet model:', model_efficientnet)\n        self.model3 = CassvaImgClassifier(model_resnext50, n_class, pretrained)\n        print('Resnext model:', model_resnext50)\n        \n    def forward(self, x):\n        x1 = self.model1(x)\n        x2 = self.model2(x)\n        x3 = self.model3(x)\n        # apply weights to the models' predictions\n        return 0.4 * x1 + 0.4 * x2 + 0.2 * x3\n    \n    def load_efficientnet(self, state_dict):\n        self.model2.load_state_dict(state_dict)\n        \n    def load_resnet(self, state_dict):\n        self.model3.load_state_dict(state_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def smooth_one_hot(true_labels: torch.Tensor, classes: int, smoothing):\n    \"\"\"\n    smooth_one_hot function: label smoothing is a regularization method to restraint the logit value for the \n    correct class to be closer to the logit values for other classes\n    input:\n    true_labels: two dimension tensor with the batches of the target variables\n    smoothing: float number\n    if smoothing == 0, it's one-hot method\n    if 0 < smoothing < 1, it's smooth method\n\n    \"\"\"\n    assert 0 <= smoothing < 1\n    confidence = 1.0 - smoothing\n    label_shape = torch.Size((true_labels.size(0), classes))\n    with torch.no_grad():\n        true_dist = torch.empty(size=label_shape, device=true_labels.device)\n        true_dist.fill_(smoothing / (classes - 1))\n        # true_labels.data.unsqueeze shape torch.Size([32, 1]) (32 train batches with the label value)\n        # true_dist tensor is filled with confidence score according to the index (true_labels.data.unsqueeze(1))\n        true_dist.scatter_(1, true_labels.data.unsqueeze(1), confidence)\n        true_dist = true_dist.type(torch.cuda.HalfTensor)\n    return true_dist","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Main Loop\ndef inference_one_epoch(model, data_loader, device):\n    '''\n    inference_one_epoch function: predict the input data\n    input:\n    data_loader: pytorch dataloader object that contains the data batches\n    '''\n    model.eval()\n    image_preds_all = []\n    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n    \n    for step, (imgs) in pbar:\n        imgs = imgs.to(device).float()\n        image_preds = model(imgs)   #output = model(input)\n        # image_preds: positive to negative float number\n        # apply softmax function with 1 dimension\n        # image_preds np array (32, 5)\n        image_preds_all += [torch.softmax(image_preds, 1).detach().cpu().numpy()]\n        # image_preds_all: porbability of the predicted image in batch\n        \n    image_preds_all = np.concatenate(image_preds_all, axis=0)\n    return image_preds_all","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if __name__ == '__main__':\n    '''\n    Perform the 5 fold prediction on the test dataset and take the mean of the predicted value from each fold.'''\n\n    seed_everything(CFG['seed'])\n    \n    folds = StratifiedKFold(n_splits=CFG['fold_num']).split(np.arange(train.shape[0]), train.label.values)\n    folds_pred_lst = []\n    for fold, (trn_idx, val_idx) in enumerate(folds):\n        # conduct 2 fold prediction\n        if fold > 1:\n            break \n\n        print('Inference fold {} started'.format(fold))\n\n        valid_ = train.loc[val_idx,:].reset_index(drop=True)\n        # preprocess the image, and extract the image array \n        valid_ds = CassavaDataset(valid_, '../input/cassava-leaf-disease-classification/train_images/', transforms=get_inference_transforms(), output_label=False)\n        \n        test = pd.DataFrame()\n        test['image_id'] = list(os.listdir('../input/cassava-leaf-disease-classification/test_images/'))\n        test_ds = CassavaDataset(test, '../input/cassava-leaf-disease-classification/test_images/', transforms=get_inference_transforms(), output_label=False)\n        \n        val_loader = torch.utils.data.DataLoader(\n            valid_ds, \n            batch_size=CFG['valid_bs'],\n            num_workers=CFG['num_workers'],\n            shuffle=False,\n            pin_memory=False,\n        )\n        \n        tst_loader = torch.utils.data.DataLoader(\n            test_ds, \n            batch_size=CFG['valid_bs'],\n            num_workers=CFG['num_workers'],\n            shuffle=False,\n            pin_memory=False,\n        )\n\n        device = torch.device(CFG['device'])\n#         model = CassvaImgClassifier(CFG['model_arch'], train.label.nunique()).to(device)\n        model = EnsembleClassifier(CFG['model_efficientnet'], CFG['model_resnext50'], train.label.nunique()).to(device)\n        \n        val_preds = []\n        tst_preds = []\n        model_efficientnet_b4ns = ['tf_efficientnet_b4_ns_fold_0_8', 'tf_efficientnet_b4_ns_fold_0_9','tf_efficientnet_b4_ns_fold_1_8','tf_efficientnet_b4_ns_fold_1_9']\n        model_resnext5 = ['resnext50_32x4d_fold_1_6', 'resnext50_32x4d_fold_1_6', 'resnext50_32x4d_fold_1_9', 'resnext50_32x4d_fold_1_9']\n        \n        for i, (model_efficientnet, model_resnext50) in enumerate(zip(model_efficientnet_b4ns, model_resnext5)):  \n            print(f'load model /kaggle/input/tfefficientnetb4ns6/{model_efficientnet}')\n            print(f'load model /kaggle/input/resnext/{model_resnext50}')\n            model.load_efficientnet(torch.load('/kaggle/input/tfefficientnetb4ns6/{}'.format(model_efficientnet)))\n            model.load_resnet(torch.load('/kaggle/input/resnext/{}'.format(model_resnext50)))\n            # no backpropagation\n            with torch.no_grad():\n                for _ in range(CFG['tta']):\n                    #inference_one_epoch output the batch predictions\n                    #scale the probability to 1/12, and concatenate the prediction into a list\n                    val_preds += [CFG['weights'][i]/4/CFG['tta']*inference_one_epoch(model, val_loader, device)]\n                    tst_preds += [CFG['weights'][i]/4/CFG['tta']*inference_one_epoch(model, tst_loader, device)]\n                torch.cuda.empty_cache()\n        # compute the mean of the scaled probability from 3 models(resnext, visiontransformer and tf_efficientnet_b4ns)\n        val_preds = np.mean(val_preds, axis=0) \n        tst_preds = np.mean(tst_preds, axis=0) \n        folds_pred_lst.append(tst_preds)\n        # compute log loss of the validation dataset \n        print('fold {} validation loss softmax = {:.5f}'.format(fold, log_loss(valid_.label.values, val_preds)))\n#         print('fold {} validation loss = {:.5f}'.format(fold, loss_fn(val_preds, smooth_label)))\n        # compute the accuracy rate of the batches in each fold\n        print('fold {} validation accuracy of softmax= {:.5f}'.format(fold, (valid_.label.values==np.argmax(val_preds, axis=1)).mean()))\n        \n        del model\n\n    first_test_pred = folds_pred_lst[0]\n    snd_test_pred = folds_pred_lst[1]\n    # compute the mean value of the prediction in 2 folds\n    mean_tst_preds = np.mean(folds_pred_lst, axis=0)\n\n    print('first_test_pred:',first_test_pred)\n    print('snd_test_pred:',snd_test_pred)\n    print('mean_tst_preds:',mean_tst_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['label'] = np.argmax(mean_tst_preds, axis=1)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.to_csv('submission.csv', index=False)\n# valid_df.to_csv('valid_entry.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}